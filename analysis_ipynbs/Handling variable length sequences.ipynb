{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "60c3dccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "aa95ebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq1 = torch.randn(50, 1)\n",
    "seq2 = torch.randn(60, 1)\n",
    "seq3 = torch.randn(2, 1)\n",
    "seq4 = torch.randn(10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "49e7c0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pad_sequence in module torch.nn.utils.rnn:\n",
      "\n",
      "pad_sequence(sequences, batch_first=False, padding_value=0.0)\n",
      "    Pad a list of variable length Tensors with ``padding_value``\n",
      "    \n",
      "    ``pad_sequence`` stacks a list of Tensors along a new dimension,\n",
      "    and pads them to equal length. For example, if the input is list of\n",
      "    sequences with size ``L x *`` and if batch_first is False, and ``T x B x *``\n",
      "    otherwise.\n",
      "    \n",
      "    `B` is batch size. It is equal to the number of elements in ``sequences``.\n",
      "    `T` is length of the longest sequence.\n",
      "    `L` is length of the sequence.\n",
      "    `*` is any number of trailing dimensions, including none.\n",
      "    \n",
      "    Example:\n",
      "        >>> from torch.nn.utils.rnn import pad_sequence\n",
      "        >>> a = torch.ones(25, 300)\n",
      "        >>> b = torch.ones(22, 300)\n",
      "        >>> c = torch.ones(15, 300)\n",
      "        >>> pad_sequence([a, b, c]).size()\n",
      "        torch.Size([25, 3, 300])\n",
      "    \n",
      "    Note:\n",
      "        This function returns a Tensor of size ``T x B x *`` or ``B x T x *``\n",
      "        where `T` is the length of the longest sequence. This function assumes\n",
      "        trailing dimensions and type of all the Tensors in sequences are same.\n",
      "    \n",
      "    Arguments:\n",
      "        sequences (list[Tensor]): list of variable length sequences.\n",
      "        batch_first (bool, optional): output will be in ``B x T x *`` if True, or in\n",
      "            ``T x B x *`` otherwise\n",
      "        padding_value (float, optional): value for padded elements. Default: 0.\n",
      "    \n",
      "    Returns:\n",
      "        Tensor of size ``T x B x *`` if :attr:`batch_first` is ``False``.\n",
      "        Tensor of size ``B x T x *`` otherwise\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pad_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d25c64a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sequence = pad_sequence(sequences=[seq1, \n",
    "                                          seq2,\n",
    "                                          seq3,\n",
    "                                          seq4], batch_first=True, padding_value=-1000)\n",
    "lens = [seq.size(0) for seq in [seq1, seq2, seq3, seq4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0e02692a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 60, 2, 10]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dcbf95ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 60, 1])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequence.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6dc88af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.4193e-01],\n",
       "        [ 1.2174e+00],\n",
       "        [-3.0194e-01],\n",
       "        [-1.2784e+00],\n",
       "        [-6.8767e-01],\n",
       "        [ 8.0987e-01],\n",
       "        [-8.5511e-02],\n",
       "        [-3.3943e-01],\n",
       "        [ 5.8664e-01],\n",
       "        [-2.1247e-01],\n",
       "        [ 2.2592e-01],\n",
       "        [ 2.4989e+00],\n",
       "        [-9.6000e-01],\n",
       "        [-4.2262e-01],\n",
       "        [ 6.4699e-01],\n",
       "        [-1.8023e+00],\n",
       "        [ 5.4731e-01],\n",
       "        [ 3.2625e-01],\n",
       "        [-9.6760e-01],\n",
       "        [ 1.3899e+00],\n",
       "        [ 1.0241e+00],\n",
       "        [ 3.7540e+00],\n",
       "        [-7.3970e-01],\n",
       "        [ 6.8482e-01],\n",
       "        [ 1.0996e+00],\n",
       "        [ 1.4202e+00],\n",
       "        [ 3.0433e-01],\n",
       "        [ 7.7881e-01],\n",
       "        [-1.2369e-01],\n",
       "        [-1.0651e+00],\n",
       "        [ 6.8292e-01],\n",
       "        [-7.2316e-01],\n",
       "        [ 7.0480e-01],\n",
       "        [-6.4630e-01],\n",
       "        [ 9.4085e-01],\n",
       "        [ 4.8894e-01],\n",
       "        [ 3.6962e-01],\n",
       "        [-2.6323e-01],\n",
       "        [ 7.8854e-01],\n",
       "        [-1.1166e+00],\n",
       "        [ 1.1667e+00],\n",
       "        [-3.1645e-01],\n",
       "        [-2.6030e-01],\n",
       "        [-3.1776e+00],\n",
       "        [ 5.7874e-01],\n",
       "        [-2.4311e-02],\n",
       "        [-9.3342e-01],\n",
       "        [ 1.6932e+00],\n",
       "        [-6.5510e-01],\n",
       "        [-1.6526e+00],\n",
       "        [-1.0000e+03],\n",
       "        [-1.0000e+03],\n",
       "        [-1.0000e+03],\n",
       "        [-1.0000e+03],\n",
       "        [-1.0000e+03],\n",
       "        [-1.0000e+03],\n",
       "        [-1.0000e+03],\n",
       "        [-1.0000e+03],\n",
       "        [-1.0000e+03],\n",
       "        [-1.0000e+03]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dd20fcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_padded_sequence = pack_padded_sequence(input=padded_sequence, lengths=lens, batch_first=True, enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4254196b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([122, 1])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_padded_sequence.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "64ddd174",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.GRU(input_size=1, hidden_size=2, num_layers=1, \n",
    "             bias=True, batch_first=True, dropout=0.0, \n",
    "             bidirectional=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3b896e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hn = rnn.forward(packed_padded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "52941406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([122, 2])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e78f9d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1 = nn.Linear(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1d8300ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states_unpacked, lens_unpacked = pad_packed_sequence(sequence=out, batch_first=True, padding_value=-1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ae159069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 60, 2])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states_unpacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1d57ef55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.1862e-01, -1.2859e-02],\n",
       "         [-2.6092e-01,  3.4482e-01],\n",
       "         [-3.2502e-01,  1.9340e-01],\n",
       "         [-3.8103e-01, -8.8216e-02],\n",
       "         [-4.2686e-01, -7.9546e-02],\n",
       "         [-3.5748e-01,  2.1930e-01],\n",
       "         [-3.7610e-01,  1.8971e-01],\n",
       "         [-3.9780e-01,  1.2041e-01],\n",
       "         [-3.5671e-01,  2.8033e-01],\n",
       "         [-3.7753e-01,  1.8695e-01],\n",
       "         [-3.7080e-01,  2.4100e-01],\n",
       "         [-1.2542e-01,  5.9188e-01],\n",
       "         [-2.2503e-01,  1.1186e-01],\n",
       "         [-3.2497e-01,  7.4123e-02],\n",
       "         [-3.2873e-01,  2.7648e-01],\n",
       "         [-3.7665e-01, -1.6827e-01],\n",
       "         [-3.6958e-01,  1.3300e-01],\n",
       "         [-3.6408e-01,  2.3779e-01],\n",
       "         [-4.0322e-01, -1.6404e-03],\n",
       "         [-2.8486e-01,  3.5215e-01],\n",
       "         [-2.6827e-01,  4.6728e-01],\n",
       "         [ 6.4164e-02,  7.6619e-01],\n",
       "         [-9.7058e-02,  2.0611e-01],\n",
       "         [-2.4161e-01,  3.5978e-01],\n",
       "         [-2.4850e-01,  4.8555e-01],\n",
       "         [-2.1482e-01,  5.8316e-01],\n",
       "         [-2.6862e-01,  4.1707e-01],\n",
       "         [-2.7703e-01,  4.5064e-01],\n",
       "         [-3.2225e-01,  2.7393e-01],\n",
       "         [-3.7455e-01, -1.0771e-02],\n",
       "         [-3.4807e-01,  2.3759e-01],\n",
       "         [-3.8939e-01,  5.3678e-02],\n",
       "         [-3.4744e-01,  2.7124e-01],\n",
       "         [-3.8566e-01,  8.4551e-02],\n",
       "         [-3.2300e-01,  3.2735e-01],\n",
       "         [-3.2279e-01,  3.5684e-01],\n",
       "         [-3.2830e-01,  3.4473e-01],\n",
       "         [-3.6040e-01,  2.0156e-01],\n",
       "         [-3.2190e-01,  3.5716e-01],\n",
       "         [-3.7004e-01,  7.4791e-03],\n",
       "         [-3.0058e-01,  3.2809e-01],\n",
       "         [-3.4787e-01,  1.8320e-01],\n",
       "         [-3.8029e-01,  1.3617e-01],\n",
       "         [-4.0878e-01, -4.2247e-01],\n",
       "         [-3.9385e-01, -5.8601e-03],\n",
       "         [-4.0367e-01,  9.9530e-02],\n",
       "         [-4.3517e-01, -4.9813e-02],\n",
       "         [-2.5695e-01,  3.6275e-01],\n",
       "         [-3.2591e-01,  1.1654e-01],\n",
       "         [-3.8349e-01, -1.9494e-01],\n",
       "         [-1.0000e+03, -1.0000e+03],\n",
       "         [-1.0000e+03, -1.0000e+03],\n",
       "         [-1.0000e+03, -1.0000e+03],\n",
       "         [-1.0000e+03, -1.0000e+03],\n",
       "         [-1.0000e+03, -1.0000e+03],\n",
       "         [-1.0000e+03, -1.0000e+03],\n",
       "         [-1.0000e+03, -1.0000e+03],\n",
       "         [-1.0000e+03, -1.0000e+03],\n",
       "         [-1.0000e+03, -1.0000e+03],\n",
       "         [-1.0000e+03, -1.0000e+03]], grad_fn=<SelectBackward>),\n",
       " tensor(50),\n",
       " tensor([[-0.2186, -0.0129],\n",
       "         [-0.2609,  0.3448],\n",
       "         [-0.3250,  0.1934],\n",
       "         [-0.3810, -0.0882],\n",
       "         [-0.4269, -0.0795],\n",
       "         [-0.3575,  0.2193],\n",
       "         [-0.3761,  0.1897],\n",
       "         [-0.3978,  0.1204],\n",
       "         [-0.3567,  0.2803],\n",
       "         [-0.3775,  0.1869],\n",
       "         [-0.3708,  0.2410],\n",
       "         [-0.1254,  0.5919],\n",
       "         [-0.2250,  0.1119],\n",
       "         [-0.3250,  0.0741],\n",
       "         [-0.3287,  0.2765],\n",
       "         [-0.3767, -0.1683],\n",
       "         [-0.3696,  0.1330],\n",
       "         [-0.3641,  0.2378],\n",
       "         [-0.4032, -0.0016],\n",
       "         [-0.2849,  0.3521],\n",
       "         [-0.2683,  0.4673],\n",
       "         [ 0.0642,  0.7662],\n",
       "         [-0.0971,  0.2061],\n",
       "         [-0.2416,  0.3598],\n",
       "         [-0.2485,  0.4856],\n",
       "         [-0.2148,  0.5832],\n",
       "         [-0.2686,  0.4171],\n",
       "         [-0.2770,  0.4506],\n",
       "         [-0.3222,  0.2739],\n",
       "         [-0.3746, -0.0108],\n",
       "         [-0.3481,  0.2376],\n",
       "         [-0.3894,  0.0537],\n",
       "         [-0.3474,  0.2712],\n",
       "         [-0.3857,  0.0846],\n",
       "         [-0.3230,  0.3273],\n",
       "         [-0.3228,  0.3568],\n",
       "         [-0.3283,  0.3447],\n",
       "         [-0.3604,  0.2016],\n",
       "         [-0.3219,  0.3572],\n",
       "         [-0.3700,  0.0075],\n",
       "         [-0.3006,  0.3281],\n",
       "         [-0.3479,  0.1832],\n",
       "         [-0.3803,  0.1362],\n",
       "         [-0.4088, -0.4225],\n",
       "         [-0.3938, -0.0059],\n",
       "         [-0.4037,  0.0995],\n",
       "         [-0.4352, -0.0498],\n",
       "         [-0.2570,  0.3627],\n",
       "         [-0.3259,  0.1165],\n",
       "         [-0.3835, -0.1949]], grad_fn=<SliceBackward>))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states_unpacked[0], lens_unpacked[0], hidden_states_unpacked[0,:lens_unpacked[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bf59c6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = fc1(hidden_states_unpacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c750d133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 60, 1])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "44a511c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.4895, -0.4597,  1.0238]) tensor([ 0.4628, -0.3795,  0.4999])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3,)\n",
    "b = a / (1.0 + a**2)\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fec3fdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.3440e-01],\n",
       "        [ 5.2169e-01],\n",
       "        [ 3.0555e-01],\n",
       "        [ 4.8630e-01],\n",
       "        [ 5.5042e-01],\n",
       "        [ 6.7441e-01],\n",
       "        [ 6.3157e-01],\n",
       "        [ 4.1873e-01],\n",
       "        [ 4.6184e-01],\n",
       "        [ 4.0588e-01],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02],\n",
       "        [-6.2850e+02]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0db687d",
   "metadata": {},
   "source": [
    "## Experimenting with refactored dynamics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "aac65c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_dynamics_fn(x_k):\n",
    "    gamma = 0.8\n",
    "    n_states = x_k.shape[-1]\n",
    "    F_mat = torch.eye(n_states) + torch.concatenate((torch.zeros(n_states, 1), \n",
    "                                                torch.concatenate((torch.ones(1, n_states-1), \n",
    "                                                                torch.zeros(n_states-1, n_states-1)), \n",
    "                                                               dim=0)\n",
    "                                                ), \n",
    "                                                dim=1)\n",
    "        \n",
    "    F_mat = F_mat.type(torch.FloatTensor) * gamma\n",
    "    assert (torch.eig(F_mat)[0] <= 1.0).all() == True, \"System is not stable!\"\n",
    "    x_k_plus_1 = F_mat @ x_k\n",
    "    return x_k_plus_1\n",
    "\n",
    "def nonlinear1d_dynamics_fn(x_k, k, a=0.5, b=25.0, c=8.0):\n",
    "    x_k_plus_1 = a * x_k + b * (x_k / (1.0 + x_k**2)) + c * torch.cos(1.2 * (k+1)) \n",
    "    return x_k_plus_1\n",
    "\n",
    "def lorenz63_dynamics_fn(x_k, J=5, delta=0.02):\n",
    "    \n",
    "    n_states = x_k.shape[-1]\n",
    "    A_mat = torch.Tensor([\n",
    "        [-10.0, 10.0, 0.0],\n",
    "        [28.0, - 1.0, -x_k[0]],\n",
    "        [0.0, x_k[0], -8.0/3] \n",
    "    ]).type(torch.FloatTensor) \n",
    "    F_k = torch.eye(n_states, n_states).type(torch.FloatTensor)\n",
    "    for j in range(1, J+1):\n",
    "        #self.F += np.linalg.matrix_power(self.A_fn(x)*self.delta, j) / np.math.factorial(j)\n",
    "        F_k += torch.matrix_power(A_mat*delta, j) / math.factorial(j)\n",
    "\n",
    "    x_k_plus_1 = F_k @ x_k\n",
    "    return x_k_plus_1\n",
    "\n",
    "def chen_dynamics_fn(x_k, J=5, delta=0.002, alpha=0.0):\n",
    "    \n",
    "    n_states = x_k.shape[-1]\n",
    "    A_mat = torch.Tensor([\n",
    "        [-35.0, 35.0, 0.0],\n",
    "        [-7.0, 28.0, -x_k[0]],\n",
    "        [0.0, x_k[0], -3.0] \n",
    "    ]).type(torch.FloatTensor) \n",
    "    F_k = torch.eye(n_states, n_states).type(torch.FloatTensor)\n",
    "    for j in range(1, J+1):\n",
    "        #self.F += np.linalg.matrix_power(self.A_fn(x)*self.delta, j) / np.math.factorial(j)\n",
    "        F_k += torch.matrix_power(A_mat*delta, j) / math.factorial(j)\n",
    "\n",
    "    x_k_plus_1 = F_k @ x_k\n",
    "    return x_k_plus_1\n",
    "\n",
    "def rossler_dynamics_fn(x_k, J=5, delta=0.008, a=0.2, b=0.2, c=5.7):\n",
    "    \n",
    "    n_states = x_k.shape[-1]\n",
    "    A_mat = torch.Tensor([\n",
    "        [0, -1, -1],\n",
    "        [1, a, 0],\n",
    "        [0, 0, (b / x_k[2]) + (x_k[0] - c)]\n",
    "    ]).type(torch.FloatTensor) \n",
    "    F_k = torch.eye(n_states, n_states).type(torch.FloatTensor) \n",
    "    for j in range(1, J+1):\n",
    "        #self.F += np.linalg.matrix_power(self.A_fn(x)*self.delta, j) / np.math.factorial(j)\n",
    "        F_k += torch.matrix_power(A_mat*delta, j) / math.factorial(j)\n",
    "\n",
    "    x_k_plus_1 = F_k @ x_k\n",
    "    return x_k_plus_1 \n",
    "\n",
    "def lorenz96_process_model(T_time, n_states, method='RK45', N=20, F_mu=8.0, delta=0.01, sigma_e2_dB=-10.0):\n",
    "\n",
    "    def L96(t, x, N=20, F_mu=8.0, sigma_e2=.1):\n",
    "        \"\"\"Lorenz 96 model with constant forcing\n",
    "        Adapted from: https://www.wikiwand.com/en/Lorenz_96_model \n",
    "        \"\"\"\n",
    "        # Setting up vector\n",
    "        d = np.zeros(N)\n",
    "        # Loops over indices (with operations and Python underflow indexing handling edge cases)\n",
    "        F_N = np.random.normal(loc=F_mu, scale=np.sqrt(sigma_e2), size=(N,)) # Incorporating Process noise through the forcing constant\n",
    "        for i in range(N):\n",
    "            #print(F_N[i])\n",
    "            d[i] = (x[(i + 1) % N] - x[i - 2]) * x[i - 1] - x[i] + F_N[i]\n",
    "        return d\n",
    "\n",
    "    sigma_e2 = dB_to_lin(sigma_e2_dB)\n",
    "    x0 = F_mu * np.ones(n_states)  # Initial state (equilibrium)\n",
    "    x0[0] += delta  # Add small perturbation to the first variable\n",
    "    sol = solve_ivp(L96, \n",
    "                    t_span=(0.0, T_time), \n",
    "                    y0=x0, \n",
    "                    args=(n_states, F_mu, sigma_e2,), \n",
    "                    method=method, \n",
    "                    t_eval=np.arange(0.0, T_time, delta), \n",
    "                    max_step=delta)\n",
    "\n",
    "    x_lorenz96 = torch.from_numpy(np.concatenate((sol.y.T, x0.reshape((1, -1))), axis=0)).type(torch.FloatTensor)\n",
    "    return x_lorenz96\n",
    "\n",
    "def get_dynamics_fn_dict(fn_name):\n",
    "\n",
    "    DYNAMICS_FN_LIST = {\n",
    "        \"linear\": linear_dynamics_fn,\n",
    "        \"nonlinear1d\": nonlinear1d_dynamics_fn,\n",
    "        \"lorenz63\": lorenz63_dynamics_fn,\n",
    "        \"chen\": chen_dynamics_fn,\n",
    "        \"rossler\": rossler_dynamics_fn\n",
    "    }\n",
    "\n",
    "    return DYNAMICS_FN_LIST[fn_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7b8ed52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {\n",
    "    \"nonlinear1d\": {\n",
    "        \"a\":0.5,\n",
    "        \"b\":25.0,\n",
    "        \"c\":8.0\n",
    "    }\n",
    "}\n",
    "dynamics_fn_nonlinear = get_dynamics_fn_dict(fn_name=\"nonlinear1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "41790611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.nonlinear1d_dynamics_fn(x_k, k, a=0.5, b=25.0, c=8.0)>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamics_fn_nonlinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772823a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
